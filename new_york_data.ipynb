{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "us_states = pd.read_csv('us_states.csv',sep=';',header=None,usecols=[0],names=['state_name'])\n",
    "\n",
    "#https://worldpopulationreview.com/states/\n",
    "us_state_data = pd.read_csv('us_states_pop_density.csv')\n",
    "\n",
    "sqr_mile_factor = 2.58998811\n",
    "\n",
    "us_state_data['density'] *= sqr_mile_factor\n",
    "us_state_data.set_index('State',inplace=True)\n",
    "\n",
    "def get_daily_data(f,state_name):\n",
    "    df = pd.read_csv(f,sep=',')\n",
    "    us = df.groupby('Country_Region').get_group('US')\n",
    "    state_mask = us.loc[:,'Province_State'] == state_name\n",
    "    state = us[state_mask].copy()\n",
    "    state['Last_Update'] = pd.to_datetime(state['Last_Update'])\n",
    "    state['Last_Update'] = state['Last_Update'].dt.date\n",
    "    return state\n",
    "\n",
    "def get_daily_data_2(f,state_name):\n",
    "    df = pd.read_csv(f,sep=',')\n",
    "    us = df.groupby('Country/Region').get_group('US')\n",
    "    state_mask = us.loc[:,'Province/State'] == state_name\n",
    "    state = us[state_mask].copy()\n",
    "    state['Last Update'] = pd.to_datetime(state['Last Update'])\n",
    "    state['Last Update'] = state['Last Update'].dt.date\n",
    "    return state\n",
    "\n",
    "us_state_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "file_prefix = '../../corona/COVID-19/csse_covid_19_data/csse_covid_19_daily_reports/*.csv'\n",
    "\n",
    "files = [f for f in glob.glob(file_prefix)]\n",
    "files = sorted(files)\n",
    "\n",
    "file_s = pd.Series(files)\n",
    "change_idx = 59\n",
    "\n",
    "\n",
    "def process_state(state_name):\n",
    "\n",
    "    timeline_df_1 = pd.DataFrame()\n",
    "    timeline_df_2 = pd.DataFrame()\n",
    "\n",
    "    for i,f in file_s.iteritems():\n",
    "    \n",
    "    \n",
    "        if i > change_idx:\n",
    "            temp = get_daily_data(f,state_name)\n",
    "            timeline_df_1 = pd.concat([timeline_df_1,temp],axis=0)\n",
    "        else:\n",
    "            temp = get_daily_data_2(f,state_name)\n",
    "            timeline_df_2 = pd.concat([timeline_df_2,temp],axis=0)\n",
    "        \n",
    "    \n",
    "    timeline_df_1 = timeline_df_1.groupby(['Province_State','Last_Update']).sum()\n",
    "\n",
    "    timeline_df_1.drop(['FIPS','Lat','Long_','Active'],axis=1,inplace=True)\n",
    "    timeline_df_1.reset_index(inplace=True)\n",
    "    timeline_df_2.drop(['Country/Region','Latitude','Longitude'],axis=1,inplace=True)\n",
    "    timeline_df_2.rename(columns={'Province/State':'Province_State',\n",
    "                             'Last Update':'Last_Update'},inplace=True)\n",
    "\n",
    "    timeline_df = pd.concat([timeline_df_2,timeline_df_1],axis=0)\n",
    "    #timeline_df.drop(203,inplace=True) # double entry\n",
    "    #timeline_df.at[203,'Last_Update'] = pd.to_datetime('2020-03-13').date() # wrong date\n",
    "\n",
    "    timeline_df['inc'] = timeline_df['Confirmed'] - timeline_df['Confirmed'].shift()\n",
    "    timeline_df['inc_dead'] = timeline_df['Deaths'] - timeline_df['Deaths'].shift()\n",
    "    timeline_df['factor'] = timeline_df['Confirmed'] / timeline_df['Confirmed'].shift()\n",
    "    timeline_df['factor_dead'] = timeline_df['Deaths'] / timeline_df['Deaths'].shift()\n",
    "    timeline_df.replace(np.inf,np.nan,inplace=True)\n",
    "\n",
    "    timeline_df.columns = ['state','date','confirmed','dead','recovered','inc','inc_dead',\n",
    "                       'factor','factor_dead']\n",
    "\n",
    "    timeline_df.set_index('date',inplace=True)\n",
    "    timeline_df.drop('state',axis=1,inplace=True)\n",
    "    \n",
    "    timeline_df['density'] = us_state_data.loc[state_name,'density']\n",
    "    timeline_df['population'] = us_state_data.loc[state_name,'Pop']\n",
    "    \n",
    "    \n",
    "    timeline_df.rename(columns={'dead': 'deceased',\n",
    "                      'inc_dead':'dead_inc',\n",
    "                      'factor_dead' :'dead_factor'},inplace=True)\n",
    "    \n",
    "    timeline_df['conf_per_M'] = timeline_df['confirmed'] / (us_state_data.loc[state_name,'Pop'] / 1e6)\n",
    "    timeline_df['dead_per_M'] = timeline_df['deceased'] / (us_state_data.loc[state_name,'Pop'] / 1e6)\n",
    "                    \n",
    "    #timeline_df.to_pickle('US_states_{}_timeline.pkl'.format(state_name))\n",
    "    return timeline_df\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_states['state_name'] = us_states['state_name'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "us_state_dict = dict()\n",
    "\n",
    "for i,s in us_states['state_name'].iteritems():\n",
    "    \n",
    "    state = process_state(s)\n",
    "    us_state_dict[s] = state\n",
    "\n",
    "ny = us_state_dict['New York']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ny.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#patch erroneous date\n",
    "\n",
    "ny.at[3,'date'] = pd.to_datetime('2020-03-13').date()\n",
    "ny = ny.set_index('date')\n",
    "us_state_dict['New York'] = ny\n",
    "\n",
    "us_state_dict['New York']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_state_dict['New York']\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open ('us_state_dict.pkl','wb') as f:\n",
    "    pickle.dump(us_state_dict,f,pickle.HIGHEST_PROTOCOL)\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
