{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/towards-better-estimates-of-recovered-covid-19-cases-d6d1e35b8bda #\n",
    "# https://towardsdatascience.com/false-positives-negatives-and-bayes-rule-for-covid-19-testing-750eaba84acd #\n",
    "# https://towardsdatascience.com/bayes-rule-with-a-simple-and-practical-example-2bce3d0f4ad0 #\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd \n",
    "import pymc3 as pm\n",
    "import arviz as az\n",
    "from scipy.special import binom as bin_coeff\n",
    "\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### set 3:d param True if you want P(infected | positive test) ###\n",
    "### set 3:d param False if you want p(healthy | negative test) ###\n",
    "### base_rate == Prior. If testing for P(healthy | neg), set base_rate to 1 - incidence ###\n",
    "\n",
    "def bayes_rule(base_rate,sensitivity,specificity,p_inf_given_pos = True):\n",
    "    true_pos = base_rate * sensitivity\n",
    "    false_neg = base_rate * (1 - sensitivity)\n",
    "    true_neg = (1 - base_rate) * specificity\n",
    "    false_pos =  (1 - base_rate) * (1 - specificity)\n",
    "    \n",
    "    if p_inf_given_pos:\n",
    "        return true_pos / (true_pos + false_pos)\n",
    "    else:\n",
    "        return true_neg / (true_neg + false_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incidence = 0.001\n",
    "\n",
    "sensitivity = 0.95\n",
    "specificity = 0.99\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first test positive, post becomes new incidence #\n",
    "post = bayes_rule(incidence,sensitivity,specificity) # post becomes new incidence #\n",
    "print (post)\n",
    "\n",
    "# second test negative,post becomes p(healthy) #\n",
    "post = bayes_rule(post,sensitivity,specificity,p_inf_given_pos=False) # post becomes inverse of incidence #\n",
    "print (1-post)\n",
    "\n",
    "# third test negative,post becomes p(healthy) # \n",
    "post = bayes_rule(1-post,sensitivity,specificity,p_inf_given_pos=False) # must invert post #\n",
    "print (1-post)\n",
    "\n",
    "# fourth test negative, post becomes p(healthy) #\n",
    "post = bayes_rule(1-post,sensitivity,specificity,p_inf_given_pos=False) # must invert post #\n",
    "print (1-post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_sequence(test_outcome,incidence,sensitivity,specificity):\n",
    "\n",
    "    prob_infected_after_test = np.zeros(len(test_outcome))\n",
    "\n",
    "    post = incidence\n",
    "\n",
    "    for i,t in enumerate(test_outcome):\n",
    "\n",
    "        post = bayes_rule(post,sensitivity,specificity,p_inf_given_pos=test_outcome[i])\n",
    "\n",
    "        if test_outcome[i] == False: # post now represents p(inverse of infected) i.e. p(healthy)\n",
    "            post = 1 - post # take the complement as the updated incidence\n",
    "\n",
    "        prob_infected_after_test[i] = post\n",
    "\n",
    "    prob_infected_after_test\n",
    "\n",
    "    outcome_map = {True : 'Positive',False : 'Negative'}\n",
    "\n",
    "    test_df = pd.DataFrame({'test_outcome' : [outcome_map[test_outcome[i]] for i in range(len(test_outcome))],\n",
    "                           'p_infected_given_test_sequence' : prob_infected_after_test})\n",
    "\n",
    "    test_df.index = range(1,len(test_df) + 1)\n",
    "    test_df.index.name='test nr'\n",
    "    \n",
    "    return test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_outcome = [True,False] * 5\n",
    "\n",
    "foo = test_sequence(test_outcome,incidence,sensitivity,specificity)\n",
    "\n",
    "foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = foo.plot(y='p_infected_given_test_sequence',style='o--',figsize=(18,12))\n",
    "\n",
    "status_2_color = {'Positive' : 'red','Negative' : 'green'}\n",
    "\n",
    "xyz = zip(foo.index,foo['p_infected_given_test_sequence'],foo['test_outcome'])\n",
    "for i,(x,y,status) in enumerate (xyz):\n",
    "    ax.annotate(xy=(x,y),text=status[:3], color=status_2_color[status])\n",
    "    \n",
    "ax.set_ylabel('P ( infected | test sequence )')\n",
    "ax.set_xlabel('Test Outcome Sequence')\n",
    "ax.set_xticks(range(1,len(foo) + 1 ))\n",
    "plt.title('Probability infected given test sequence, incidence : {:.3f}, sensitivity : {:.3f} specificity : {:.3f}'.format(\n",
    "incidence,sensitivity,specificity))\n",
    "plt.legend(loc='upper left')\n",
    "plt.savefig('bayesian_update_incidence_impact.jpg',format='jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_rates = np.linspace(0,0.1,100)\n",
    "p_inf_g_pos = bayes_rule(base_rates,sensitivity,specificity)\n",
    "#p_inf_g_pos = bayes_rule(base_rates,0.97,0.95) # example from link 3 above #\n",
    "\n",
    "\n",
    "plt.figure(figsize=(18,12))\n",
    "plt.plot(base_rates,p_inf_g_pos)\n",
    "plt.ylabel('P(infected | positive test)')\n",
    "plt.xlabel('incidence')\n",
    "plt.title('P(infected | positive test) given different incidence rates. Sensitivity : {:.3f} Specificity : {:.3f}'.format(\n",
    "sensitivity,specificity))\n",
    "\n",
    "plt.axvline(base_rates[1],color='orange',ls='dashed')\n",
    "plt.axhline(p_inf_g_pos[1],color='orange',ls='dashed')\n",
    "\n",
    "plt.yticks(np.arange(0,1,0.05))\n",
    "\n",
    "plt.savefig('bayesian_update_p_infected_given_incidence.jpg',format='jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(2,figsize=(18,12))\n",
    "\n",
    "test_outcome = [True,False,False,False]\n",
    "\n",
    "test_df = test_sequence(test_outcome,incidence,sensitivity,specificity)\n",
    "test_df['p_healthy_given_test_sequence'] = 1 - test_df['p_infected_given_test_sequence']\n",
    "test_df.plot(ax=axes[0],x='test_outcome',y='p_infected_given_test_sequence',style='o--')\n",
    "axes[0].set_ylabel('P ( infected | test sequence )')\n",
    "axes[0].set_ylabel('Test Outcome Sequence')\n",
    "print (test_df.head())\n",
    "\n",
    "test_outcome = [True,True,True,True]\n",
    "\n",
    "test_df = test_sequence(test_outcome,incidence,sensitivity,specificity)\n",
    "test_df['p_healthy_given_test_sequence'] = 1 - test_df['p_infected_given_test_sequence']\n",
    "test_df.plot(ax=axes[1],x='test_outcome',y='p_infected_given_test_sequence',style='o--')\n",
    "axes[1].set_ylabel('P ( infected | test sequence )')\n",
    "axes[1].set_ylabel('Test Outcome Sequence')\n",
    "\n",
    "\n",
    "print (test_df.head())\n",
    "\n",
    "fig.suptitle('Bayesian Updating : Probability of being infected after n test outcomes\\n' +\\\n",
    "'incidence : {:.3f} sensitivity : {:.3f} specificity : {:.2f}'.format(incidence,sensitivity,specificity))\n",
    "\n",
    "plt.savefig('bayesian_update_pos_seq_neg_seg.jpg',format='jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Bayesian Updating : Probability of being infected after n test outcomes\\n' +\\\n",
    "'incidence : {:.3f} sensitivity : {:.3f} specificity : {:.2f}'.format(incidence,sensitivity,specificity)\n",
    "\n",
    "test_df.plot(x='test_outcome',y='p_infected_given_test_sequence',style='o--',figsize=(18,12),title=title)\n",
    "plt.ylabel('Probability being infected after sequence of tests')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.random.beta(100,3,1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### pymc to figure out distributions inci,se,sp,prop_tot_pos given 1094 positive out of 100000 pop ### \n",
    "\n",
    "# https://towardsdatascience.com/towards-better-estimates-of-recovered-covid-19-cases-d6d1e35b8bda #\n",
    "# https://towardsdatascience.com/false-positives-negatives-and-bayes-rule-for-covid-19-testing-750eaba84acd #\n",
    "# https://towardsdatascience.com/bayes-rule-with-a-simple-and-practical-example-2bce3d0f4ad0 #\n",
    "\n",
    "population = 100000\n",
    "k = 1094 # tested positive : total positive\n",
    "\n",
    "claimed_se = 0.95\n",
    "claimed_sp = 0.99\n",
    "\n",
    "with pm.Model() as model:\n",
    "    se = pm.Beta('se',100,5)\n",
    "    sp = pm.Beta('sp',100,5)\n",
    "    inci = pm.Uniform('inci',0,0.3)\n",
    "    \n",
    "    # prop_tot_pos represents proportion positive of population, true_positive + false positive # \n",
    "    prop_tot_pos = pm.Deterministic('prop_tot_pos',se * inci + (1 - inci) * (1 - sp)) # total positive\n",
    "\n",
    "    obs = pm.Binomial('obs',n=population,p=prop_tot_pos,observed=k)\n",
    "    \n",
    "    trace = pm.sample(draws=40000,tune=2000,target_accept=0.99)\n",
    "    #trace = pm.sample(draws=400,tune=20,target_accept=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    az.plot_trace(trace)\n",
    "    print (az.summary(trace))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    az.plot_posterior(trace,hdi_prob=0.89,var_names=['se'])\n",
    "    az.plot_posterior(trace,hdi_prob=0.89,var_names=['sp'])\n",
    "    az.plot_posterior(trace,hdi_prob=0.89,var_names=['inci'])\n",
    "    az.plot_posterior(trace,hdi_prob=0.89,var_names=['prop_tot_pos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model2:\n",
    "    bernoulli_trials = [0,0] * 2 + [1,1] * 2\n",
    "    \n",
    "    p = pm.Uniform('p',0,1)\n",
    "    obs = pm.Bernoulli('obs',p,observed=bernoulli_trials)\n",
    "    \n",
    "    trace2 = pm.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model2:\n",
    "    az.plot_trace(trace2)\n",
    "    print (az.summary(trace2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model2:\n",
    "    az.plot_posterior(trace2,hdi_prob=0.89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population = 100000\n",
    "\n",
    "def bayes_by_arithmetic(population, incidence,sensitivity,specificity):\n",
    "    infected = incidence * population\n",
    "    print ('infected ' ,infected)\n",
    "    healthy = population - infected \n",
    "    print ('healthy ',healthy)\n",
    "\n",
    "    true_positive = infected * sensitivity\n",
    "    print ('true positive ' , true_positive)\n",
    "    false_negative = infected - true_positive\n",
    "    print ('false negative ', false_negative)\n",
    "\n",
    "    true_negative = healthy * specificity\n",
    "    print ('true negative ', true_negative)\n",
    "    false_positive = healthy - true_negative\n",
    "    print ('false positive ', false_positive)\n",
    "\n",
    "    total_positive = true_positive + false_positive\n",
    "    print ('total_positive ',total_positive)\n",
    "\n",
    "    total_negative = true_negative + false_negative\n",
    "    print ('total negative ', total_negative)\n",
    "\n",
    "    p_infected_given_positive = true_positive / total_positive\n",
    "    print ('p_infected | positive ',p_infected_given_positive)\n",
    "    print ('p_healthy | positive ', 1 - p_infected_given_positive)\n",
    "\n",
    "    p_healthy_given_negative = true_negative / total_negative\n",
    "    print ('p_healthy | negative ', p_healthy_given_negative)\n",
    "    print ('p_infected | negative ', 1 - p_healthy_given_negative)\n",
    "    \n",
    "    return (total_positive,p_infected_given_positive,total_negative,p_healthy_given_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "tests = ['Positive','Negative','Positive','Negative','Positive','Negative','Positive']\n",
    "\n",
    "test_param_list = []\n",
    "\n",
    "test_params = bayes_by_arithmetic(population,0.001,sensitivity,specificity)\n",
    "test_param_list.append(test_params)\n",
    "print ('test params ' ,test_params)\n",
    "print ()\n",
    "\n",
    "### say your first test is positive. That means your new cohort is now test_params[0] i.e. total positive, ###\n",
    "### and the new incidence is test params[1]. So, we pass these numbers to test #2 ###\n",
    "\n",
    "test_params = bayes_by_arithmetic(test_params[0],test_params[1],sensitivity,specificity)\n",
    "test_param_list.append(test_params)\n",
    "print ('test params ',test_params)\n",
    "print ()\n",
    "\n",
    "### say the second test is negative. That means your new cohort is now test_params[2], i.e. total negative, ###\n",
    "### and the new incidence is 1 - test_params[3]\n",
    "\n",
    "test_params = bayes_by_arithmetic(test_params[2],1-test_params[3],sensitivity,specificity)\n",
    "test_param_list.append(test_params)\n",
    "print ('test params ',test_params)\n",
    "print ()\n",
    "\n",
    "### positive\n",
    "test_params = bayes_by_arithmetic(test_params[0],test_params[1],sensitivity,specificity)\n",
    "test_param_list.append(test_params)\n",
    "print ('test params ',test_params)\n",
    "print ()\n",
    "\n",
    "### negative\n",
    "test_params = bayes_by_arithmetic(test_params[2],1-test_params[3],sensitivity,specificity)\n",
    "test_param_list.append(test_params)\n",
    "print ('test params ',test_params)\n",
    "print ()\n",
    "\n",
    "# positive\n",
    "test_params = bayes_by_arithmetic(test_params[0],test_params[1],sensitivity,specificity)\n",
    "test_param_list.append(test_params)\n",
    "print ('test params ',test_params)\n",
    "print ()\n",
    "\n",
    "# negative\n",
    "test_params = bayes_by_arithmetic(test_params[2],1-test_params[3],sensitivity,specificity)\n",
    "test_param_list.append(test_params)\n",
    "print ('test params ',test_params)\n",
    "print ()\n",
    "\n",
    "\n",
    "arithmetic_df = pd.DataFrame(test_param_list)\n",
    "arithmetic_df.columns = ['total positive','p_inf_given_positive','total negative','p_healthy_given_negative']\n",
    "arithmetic_df['p_healthy_given_positive'] = 1 - arithmetic_df['p_inf_given_positive']\n",
    "arithmetic_df['p_inf_given_negative'] = 1 - arithmetic_df['p_healthy_given_negative']\n",
    "arithmetic_df['test_outcome'] = tests\n",
    "arithmetic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' So above, with the given test outcomes, our P of being infected is: \n",
    "    [0.086837,0.004780,0.313311,0.022525,0.686437,0.099556,0.913070]\n",
    "    that is, same as above using test_sequence() '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### numbers picked by 'zigzag:ing based on test outcomes above' ###\n",
    "arithmetic_outcomes = [0.086837,0.004780,0.313311,0.022525,0.686437,0.099556,0.913070]\n",
    "plt.plot(arithmetic_outcomes,'o--')\n",
    "plt.plot(foo['p_infected_given_test_sequence'].values) # cmp with results from test_sequence #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### back to theoretical Bayes example ###\n",
    "\n",
    "### simulate infected and true and the error rate of testing ###\n",
    "\n",
    "incidence = 0.001\n",
    "sensitivity = 0.95\n",
    "specificity = 0.99\n",
    "\n",
    "pop_size = 100000\n",
    "\n",
    "pop = pd.DataFrame({'infected' : np.random.choice([0,1],p=[1-incidence,incidence],size=pop_size)})\n",
    "\n",
    "pop['positive'] = pop.apply(lambda row : np.random.choice(\n",
    "    [0,1],p=[1-sensitivity,sensitivity]) if row.infected == 1 else np.random.choice(\n",
    "    [0,1],p=[specificity,1-specificity]),axis=1)\n",
    "    \n",
    "pop['false positive'] = (pop['infected'] == 0) & (pop['positive'] == 1)\n",
    "pop['false negative'] = (pop['infected'] == 1) & (pop['positive'] == 0)\n",
    "pop['true positive'] = (pop['infected'] == 1) & (pop['positive'] == 1)\n",
    "pop['true negative'] = (pop['infected'] == 0) & (pop['positive'] == 0)\n",
    "\n",
    "p_inf_g_pos = pop.sum()['true positive'] / (pop.sum()['true positive'] + pop.sum()['false positive'])\n",
    "p_ok_g_neg = pop.sum()['true negative'] / (pop.sum()['true negative'] + pop.sum()['false negative'])\n",
    "\n",
    "print ('P(inf | positive) ', p_inf_g_pos)\n",
    "print ('P(ok | negative) ', p_ok_g_neg)\n",
    "\n",
    "print (pop.sum())\n",
    "\n",
    "pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### select all positives, then pymc to figure out posterior P(infected | positive)  by \n",
    "### obs = bernoulli(p=prop_True_Pos,observed=True_Positive) ###\n",
    "### SCENARIO : having data on positives, and some means having id'd false positives (e.g. by a second test) ###\n",
    "### then: find out prob. dist for false positives by a binomial dist (N=n(positives),k=n(true positives)) ###\n",
    "\n",
    "positives = pop.loc[pop['positive'] == 1]\n",
    "print (positives.sum())\n",
    "positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model3:\n",
    "    \n",
    "    p_inf_g_pos = pm.Uniform('p_inf_g_pos',0,1)\n",
    "    obs = pm.Bernoulli('obs',p=p_inf_g_pos,observed=positives['true positive'].values)\n",
    "    \n",
    "    trace3 = pm.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model3:\n",
    "    az.plot_trace(trace3)\n",
    "    print (az.summary(trace3,hdi_prob=0.89))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model3:\n",
    "    az.plot_posterior(trace3,hdi_prob=0.89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### same as above, but with grid approximation, no prior (== uniform prior) ###\n",
    "### grid approximation of likelihood ###\n",
    "import scipy.stats as sps\n",
    "\n",
    "p = np.linspace(0,1,1000)\n",
    "\n",
    "p_inf = sps.binom.pmf(p=p,n=len(positives),k=positives['true positive'].sum())\n",
    "p_inf = p_inf / p_inf.sum()\n",
    "plt.plot(p,p_inf)\n",
    "\n",
    "plt.xlabel('p')\n",
    "plt.ylabel('plausibility')\n",
    "print ('P(infected | positive) ',p[p_inf.argmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### same, but with explicit likelihood : grid approximation by explicit binomial dist ### \n",
    "### not a distribution b/c not summing to 1 ### \n",
    "def binomial_likelihood_func_by_grid_approx(n,k,p_grid):\n",
    "    \n",
    "    prob = bin_coeff(n,k) * p_grid ** k * (1-p_grid) ** (n-k)\n",
    "    \n",
    "    return p_grid,prob\n",
    "\n",
    "n = len(positives)\n",
    "k = positives['true positive'].sum()\n",
    "\n",
    "p_grid = np.linspace(0,1,1000)\n",
    "p,lkh = binomial_likelihood_func_by_grid_approx(n,k,p_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2DO ###\n",
    "### explicit likelihood function for manual mcmc metropolis algorithm ###\n",
    "def binomial_likelihood_func_for_mcmc(n,k,proposal):\n",
    "    prob = bin_coeff(n,k) * proposal ** k * (1-proposal) ** (n-k)\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(p,lkh)\n",
    "print ('P(infected | positive) ',p[lkh.argmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### same, but now add \"weakly regulating\" prior ###\n",
    "prior = sps.beta.pdf(p_grid,2,8) # returns density, so must normalize to distribution\n",
    "prior = prior / prior.sum()\n",
    "plt.plot(p_grid,prior)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### notice how the weakly regulating prior slightly increases P ###\n",
    "posterior = prior * lkh\n",
    "posterior = posterior / posterior.sum()\n",
    "\n",
    "plt.figure(figsize=(18,12))\n",
    "\n",
    "plt.plot(p_grid,prior,label='prior')\n",
    "plt.plot(p_grid,lkh,label='lkh')\n",
    "plt.plot(p_grid,posterior,label='posterior')\n",
    "plt.legend()\n",
    "plt.ylabel('plausibility')\n",
    "plt.xlabel('posterior probability')\n",
    "print ('P(infected | positive) ',p_grid[posterior.argmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# grid approx #\n",
    "\n",
    "p_grid = np.linspace(0,1,1000)\n",
    "\n",
    "posse = pd.DataFrame([False,False,True,False,False,True,True,True,False,True,True,\n",
    "                      True,False,False,True,True,True,False,False,False,\n",
    "                     False,False,False,False,False],columns=['false positive'])\n",
    "\n",
    "#fig, axes = plt.subplots(len(posse),figsize=(18,12),sharex=True,sharey=True)\n",
    "\n",
    "k = 0\n",
    "\n",
    "### experiment by changing the prior ###\n",
    "#prior = sps.beta.pdf(p_grid,1,1) # uniform\n",
    "\n",
    "prior = sps.beta.pdf(p_grid,5,5)\n",
    "\n",
    "prior = prior / np.sum(prior)\n",
    "\n",
    "posteriors = np.zeros((len(posse),len(p_grid)))\n",
    "\n",
    "for i, (row, col) in enumerate(posse.iterrows()):\n",
    "    \n",
    "    n = i + 1\n",
    "    k += col['false positive']\n",
    "    \n",
    "    p,lkh = binomial_likelihood_func_by_grid_approx(n,k,p_grid)\n",
    "    posterior = prior * lkh\n",
    "    posterior = posterior / posterior.sum()\n",
    "    \n",
    "    posteriors[i,:] = posterior\n",
    "    \n",
    "    print (col['false positive'],n,k)\n",
    "    \n",
    "    #axes[i].plot(p,posterior,label='n : {} k : {}'.format(n,k))\n",
    "\n",
    "    #axes[i].plot(p,prior,label='prior')\n",
    "    #axes[i].legend(loc='upper center')\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_of_plots = posteriors.shape[0]\n",
    "alphas = np.arange(nr_of_plots)\n",
    "\n",
    "f = lambda x : (x - alphas.min()) / (alphas.max() - alphas.min())\n",
    "\n",
    "for i, post in enumerate(range(nr_of_plots)):\n",
    "    plt.plot(p,posteriors[post],color='k',alpha = f(alphas)[i])\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
