{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import pymc as pm\n",
    "import scipy.stats as sps\n",
    "import scipy.special as spc\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### demo poisson likelihood with one data point\n",
    "data = [6] \n",
    "lower,upper = 0,20\n",
    "\n",
    "lambda_ = pm.Uniform('lambda_',lower,upper)\n",
    "obs = pm.Poisson('obs',lambda_,observed=True,value=data)\n",
    "\n",
    "model = pm.Model([lambda_,obs])\n",
    "mcmc = pm.MCMC(model)\n",
    "samples = mcmc.sample(50000,10000,2)\n",
    "post = pd.DataFrame({'lambda' : mcmc.trace(lambda_)[:]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (post.describe())\n",
    "print (post.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull lambda samples from posterior, generate simulated data based on those lambdas\n",
    "nr_rows = 100000\n",
    "\n",
    "rows = np.random.choice(post.index,replace=True,size=nr_rows)\n",
    "posterior_samples = pm.rpoisson(post.iloc[rows,0])\n",
    "posterior_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### HOW DOES MCMC FIT THE LIKELIHOOD TO DATA ? \n",
    "\n",
    "# this attempts to solve the problem by testing a set of lambda values, and recording which of the lambdas provides \n",
    "# highest frequency of 6 (the single data point), given a number of tries per lambda.\n",
    "\n",
    "# having one data point (6), we want to find out which value for lambda gives highest frequency of \n",
    "# matches. We do so by trying each individual value for lambda, that is, the for loop with lambda below\n",
    "# acts as our (uniform) prior. \n",
    "\n",
    "nr_tries = 100000\n",
    "out = np.zeros((upper-lower+1,len(data) * nr_tries))\n",
    "\n",
    "r = 0\n",
    "c = 0\n",
    "\n",
    "for d in data:\n",
    "    \n",
    "    for lambda_ in range(lower,upper+1):\n",
    "        c = 0\n",
    "        for tries in range(nr_tries):\n",
    "            out[r,c] = pm.rpoisson(lambda_)\n",
    "            c += 1\n",
    "        r += 1       \n",
    "\n",
    "out = out.astype(int)\n",
    "freq = np.count_nonzero(out == data,axis=1)\n",
    "freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (freq)\n",
    "dist = freq / freq.sum()\n",
    "#plt.hist(post['lambda'],density=True,alpha=0.5,color='green')\n",
    "plt.bar(range(len(freq)),dist,alpha=0.5,color='red')\n",
    "plt.hist(posterior_samples,density=True,alpha=0.5,color='green',bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "ax = plt.gca()\n",
    "\n",
    "plt.plot(np.arange(len(dist)).astype(int),dist.cumsum(),'o--')\n",
    "plt.title('Cumulative Probability')\n",
    "plt.xlabel('lambda')\n",
    "plt.ylabel('probability')\n",
    "ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### https://sciencehouse.wordpress.com/2010/06/23/mcmc-and-fitting-models-to-data/\n",
    "#### demo of how to build a likelihood function to fit model to data using Metropolis-Hastings MCMC.\n",
    "#### The problem is thus to find out what parameter value p for the Binomial Distribution best matches the actual data\n",
    "###\n",
    "# error function sum of square errors: computes error between our data and what our model generates\n",
    "# sigma is an estimate of the error of data. it seems that with a small sigma, most proposals are accepted\n",
    "# but with too large sigma, runtime errors occur\n",
    "\n",
    "def X(data,generated,sigma=0.5) :\n",
    "    return (( (data - generated) ** 2) / 2 * sigma ** 2).sum()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data we want to fit. Here we KNOW the value for the parameter p we are looking for\n",
    "# it appears that the more data we have, the clearer difference about the peak there is between PYMC\n",
    "# and the hack - might be due to the error function not operating optimally\n",
    "\n",
    "SIZE = 5 # number of data points\n",
    "N = 6 # number of pulls\n",
    "true_p = 0.7 # p(success)\n",
    "\n",
    "data = pm.rbinomial(n=N,p=true_p,size=SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is our model that we want to fit, i.e the likelihood function with parameter param for p\n",
    "def generator(param,size=SIZE):\n",
    "    return pm.rbinomial(n=N,p=param,size=size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the function used by Metropolis-Hastings to determine wether to accept a proposal.\n",
    "# it uses the value returned for current and proposed errors,X_current,X_proposed, to determine \n",
    "# whether to move to the proposed new value for param p\n",
    "\n",
    "# it's basically an exponential form of the quotient proposed/current, that is, P(D|proposed_p / P(D|current_p) == \n",
    "# exp(-X_proposed **2 + X_current **2) which is based on the Gaussian Likelihood function P(D|param) = exp(-X**2)\n",
    "\n",
    "def likelihood_ratio(X_current,X_proposed):\n",
    "    return np.exp(-X_proposed ** 2 + X_current ** 2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Metropolis-Hastings MCMC algorithm for fitting binomial data. That is, we are using MCMC to search for \n",
    "### the parameter p that best matches our data\n",
    "\n",
    "\n",
    "steps = 100000 # length of MCMC random sampling walk\n",
    "\n",
    "walk = np.zeros(steps) # array of samples \n",
    "\n",
    "all_proposed = np.zeros(steps)\n",
    "all_current = np.zeros(steps)\n",
    "\n",
    "walk[0] = 0.6 #initialize first step with dummy value for param to get MCMC walk started\n",
    "\n",
    "# the random walk\n",
    "for i in range(1,steps):\n",
    "    current = walk[i-1]\n",
    "    all_current[i] = current\n",
    "    #print (current)\n",
    "    \n",
    "    # make sure proposed value for param is [0..1], which it must be for Binomial Dist.\n",
    "    while True:\n",
    "        random_step = pm.rnormal(0, 1 / 0.1 ** 2)\n",
    "        proposed = current + random_step\n",
    "        \n",
    "        if proposed >= 0 and proposed <= 1:\n",
    "            break\n",
    "    all_proposed[i] = proposed\n",
    "    \n",
    "    X_current = X(data,generator(current)) #compute error of current generated data vs real data\n",
    "    X_proposed = X(data,generator(proposed)) #compute error of proposed generated data vs real data\n",
    "    \n",
    "    A = likelihood_ratio(X_current,X_proposed) # compute ratio, i.e accept ? \n",
    "    #print (A)\n",
    "    \n",
    "    # ratio above expresses ratio of probabilities for proposed outcome vs current outcome, accoriding to distribution\n",
    "    # if ratio > 1 : accept always. if ratio < 1, accept if ratio > random number 0..1\n",
    "    # That is: if P(target) > P(current) : always accept. Else accept if random p is less than ratio. The smaller\n",
    "    # the ratio, the less chance of accept. \n",
    "    \n",
    "    if pm.runiform(0,1) < A : \n",
    "        walk[i] = proposed # accept\n",
    "    else:\n",
    "        walk[i] = current\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,12))\n",
    "plt.title('Metropolis-Hastings random sampling walk,True parameter value:{} nr of data points: {}'.format(true_p,len(data)))\n",
    "plt.xlabel ('step number')\n",
    "plt.ylabel(' acceepted and proposed parameter values')\n",
    "plt.plot(walk,'o--',label='accepted',color='navy',alpha=0.5)\n",
    "plt.plot(range(1,len(all_proposed)),all_proposed[1:],'o',color='orange',label='proposed',alpha=0.11)\n",
    "plt.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,12))\n",
    "plt.title('MCMC Metropolis Hastings with Binomial Likelihood'\\\n",
    "          ' True Parameter value: {}\\n nr of data points: {} nr of steps: {}' .format(true_p,len(data),steps))\n",
    "plt.xlabel('parameter value')\n",
    "plt.ylabel('Relative Frequency')\n",
    "_=plt.hist(walk,weights=np.ones_like(walk) / len(walk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### a look at the basics of a Gaussian\n",
    "x = np.arange(-11,12)\n",
    "y = np.exp(-x**2)\n",
    "plt.plot(x,y)\n",
    "print (y.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use PYMC for the same fitting, using uniform prior\n",
    "\n",
    "burn = 1\n",
    "thin = 1\n",
    "\n",
    "prior = pm.Uniform('prior',0,1)\n",
    "obs = pm.Binomial('obs',n=6,p=prior,observed=True,value=data)\n",
    "\n",
    "model = pm.Model([prior,obs])\n",
    "mcmc = pm.MCMC(model)\n",
    "samples = mcmc.sample(10000)\n",
    "\n",
    "result = pd.DataFrame({'post_prior' :mcmc.trace(prior)[:]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "burn = 10000\n",
    "plt.figure(figsize=(18,12))\n",
    "plt.hist(result.post_prior,density=True,label='PYMC',alpha=0.6,color='blue')\n",
    "plt.hist(walk[burn:],density=True,label='MCMC-hack',alpha=0.6,color='orange',bins=20)\n",
    "plt.legend(loc='upper left')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
